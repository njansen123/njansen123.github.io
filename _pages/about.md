---
layout: about
title: home
permalink: /
subtitle: <a href='#'></a>Associate Professor, Institute for Computing and Information Sciences, Radboud University Nijmegen.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <p>Office M1.01.05</p>
    <p>Faculty of Science</p>
    <p>Toernooiveld 212</p>
    <p>6525EC Nijmegen</p>

news: true  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

My group conducts broad foundational and application-driven research in artificial intelligence (AI). We take a broad stance on AI that brings together the areas of machine learning and formal methods, in particular formal verification. We tackle problems that are inspired by autonomous systems, industrial projects, and in particular planning problems in robotics. We use methods that use deep machine learning (ML) techniques like recurrent or graph neural networks or problems that fall into intelligent decision-making under uncertainty.
The following goals are central to our efforts:

* Increase the dependability of AI in safety-critical environments.
* Render AI models robust against uncertain knowledge about the environment they operate in.
* Enhance the capabilities of verification to handle real-world problems using learning techniques.

Summarize, we are interested in various aspects of <b>dependability, reliability and safety</b> in AI, <b>intelligent decision-making under uncertainty</b> and <b>safe reinforcement learning</b>. A key aspect of our research is a thorough understanding of the (epistemic or aleatoric) uncertainty that may occur when AI systems operate in the real world.